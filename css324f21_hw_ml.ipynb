{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "css324f21_hw_ml.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DragonZeroZzz/cifar-10-machine-learning/blob/main/css324f21_hw_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1co9QUId36Eo"
      },
      "source": [
        "# CSS324 Homework Assignment\n",
        "\n",
        "CIFAR10 is a small image classification dataset. Its objective is to classification an 32x32 color image into 10 classes.\n",
        "\n",
        "See https://www.cs.toronto.edu/~kriz/cifar.html and https://keras.io/api/datasets/cifar10/ for more details.\n",
        "\n",
        "by\n",
        "\n",
        "Sorawit Chokphantavee 6222782227\\\n",
        "Sirawit Chokphantavee 6222782250"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zXtrgRH9oK5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMSl6MYp33eW"
      },
      "source": [
        "# Load CIFAR10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Vwoz3JDK98Jy",
        "outputId": "627a3eb3-0c0b-4cb9-8228-dcbb387cd32a"
      },
      "source": [
        "# Plot a training example\n",
        "x = x_train[11, :, :, :]\n",
        "y = y_train[11][0]\n",
        "\n",
        "plt.imshow(x)\n",
        "print(y)        # 7 = horse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFt4OqeP_Buc"
      },
      "source": [
        "## Question 1\n",
        "\n",
        "Construct a deep neural network containing three hidden layer to classify images in the CIFAR10 dataset. You can choose the numbers of hidden nodes in three layers, appropriate activation functions, regularizers. Use 20% of the training set to validate the model.\n",
        "\n",
        "After the training process, print the training, validation, and test accuracies, as well as plot the training loss and validation loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpuD33bU__mt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48637876-06f1-4399-e07a-d0c0903559ec"
      },
      "source": [
        "# Your implementation for Question 1\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "(x_train, y_train) , (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Preprocessing\n",
        "y_train = tf.one_hot(y_train, 10)\n",
        "y_train = tf.reshape(y_train,[-1,10])\n",
        "y_test = tf.one_hot(y_test, 10)\n",
        "y_test = tf.reshape(y_test,[-1,10])\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(32,32,3)),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(512,activation='relu',\n",
        "    kernel_regularizer = tf.keras.regularizers.l2(1e-4)),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dropout(0.3),\n",
        "  tf.keras.layers.Dense(256,activation='relu',\n",
        "    kernel_regularizer = tf.keras.regularizers.l2(1e-4)),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(128,activation='relu',\n",
        "    kernel_regularizer = tf.keras.regularizers.l2(1e-4)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "             loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "             filepath = '/content/checkpoint',\n",
        "             save_weights_only = True,\n",
        "             monitor = 'val_accuracy',\n",
        "             mode = 'max',\n",
        "             save_best_only = True\n",
        ")\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=200, batch_size=8192,\n",
        "                    shuffle=True, validation_split=0.2, callbacks=[model_checkpoint_callback])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 3s 269ms/step - loss: 3.0372 - accuracy: 0.1857 - val_loss: 2.7248 - val_accuracy: 0.1364\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 2.5337 - accuracy: 0.2638 - val_loss: 4.6687 - val_accuracy: 0.1042\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 2.3598 - accuracy: 0.2867 - val_loss: 3.7861 - val_accuracy: 0.1239\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 2.2498 - accuracy: 0.3108 - val_loss: 3.1941 - val_accuracy: 0.1498\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 2.1846 - accuracy: 0.3212 - val_loss: 2.7882 - val_accuracy: 0.1776\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 2.1115 - accuracy: 0.3349 - val_loss: 2.5492 - val_accuracy: 0.2089\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 2.0653 - accuracy: 0.3480 - val_loss: 2.3117 - val_accuracy: 0.2450\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 2.0224 - accuracy: 0.3596 - val_loss: 2.1776 - val_accuracy: 0.2728\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 1.9838 - accuracy: 0.3692 - val_loss: 2.1314 - val_accuracy: 0.2819\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 1.9492 - accuracy: 0.3753 - val_loss: 2.0042 - val_accuracy: 0.3236\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 1.9136 - accuracy: 0.3840 - val_loss: 1.9793 - val_accuracy: 0.3317\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 1.8781 - accuracy: 0.3951 - val_loss: 1.9496 - val_accuracy: 0.3430\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 1.8580 - accuracy: 0.3995 - val_loss: 1.8979 - val_accuracy: 0.3641\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 1.8304 - accuracy: 0.4117 - val_loss: 1.8993 - val_accuracy: 0.3610\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 1s 159ms/step - loss: 1.8001 - accuracy: 0.4164 - val_loss: 1.8922 - val_accuracy: 0.3653\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 1.7787 - accuracy: 0.4209 - val_loss: 1.9056 - val_accuracy: 0.3585\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 1.7583 - accuracy: 0.4274 - val_loss: 1.8626 - val_accuracy: 0.3810\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 1s 133ms/step - loss: 1.7401 - accuracy: 0.4336 - val_loss: 1.8902 - val_accuracy: 0.3747\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 1s 143ms/step - loss: 1.7171 - accuracy: 0.4391 - val_loss: 1.8839 - val_accuracy: 0.3801\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 1.7057 - accuracy: 0.4442 - val_loss: 1.8914 - val_accuracy: 0.3811\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 1.6869 - accuracy: 0.4520 - val_loss: 1.8679 - val_accuracy: 0.3901\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 1.6773 - accuracy: 0.4527 - val_loss: 1.9016 - val_accuracy: 0.3733\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 1s 141ms/step - loss: 1.6535 - accuracy: 0.4624 - val_loss: 1.8706 - val_accuracy: 0.3879\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 1s 133ms/step - loss: 1.6490 - accuracy: 0.4628 - val_loss: 1.8855 - val_accuracy: 0.3840\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 1.6280 - accuracy: 0.4696 - val_loss: 1.9047 - val_accuracy: 0.3799\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 1.6152 - accuracy: 0.4717 - val_loss: 1.8800 - val_accuracy: 0.3872\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 1.6109 - accuracy: 0.4757 - val_loss: 1.8750 - val_accuracy: 0.3932\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 1.5974 - accuracy: 0.4772 - val_loss: 1.8633 - val_accuracy: 0.3973\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 1.5840 - accuracy: 0.4849 - val_loss: 1.8793 - val_accuracy: 0.3907\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 1.5777 - accuracy: 0.4851 - val_loss: 1.8699 - val_accuracy: 0.3978\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 1.5633 - accuracy: 0.4902 - val_loss: 1.8597 - val_accuracy: 0.4015\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 1.5547 - accuracy: 0.4909 - val_loss: 1.8461 - val_accuracy: 0.4020\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 1.5447 - accuracy: 0.4953 - val_loss: 1.8438 - val_accuracy: 0.4054\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 1.5304 - accuracy: 0.5010 - val_loss: 1.8263 - val_accuracy: 0.4133\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 1.5274 - accuracy: 0.5000 - val_loss: 1.8144 - val_accuracy: 0.4196\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 1.5172 - accuracy: 0.5072 - val_loss: 1.8250 - val_accuracy: 0.4143\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 1.5033 - accuracy: 0.5104 - val_loss: 1.8334 - val_accuracy: 0.4108\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 1.4995 - accuracy: 0.5132 - val_loss: 1.8133 - val_accuracy: 0.4176\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.4901 - accuracy: 0.5164 - val_loss: 1.7873 - val_accuracy: 0.4259\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 1.4803 - accuracy: 0.5188 - val_loss: 1.7584 - val_accuracy: 0.4351\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.4733 - accuracy: 0.5209 - val_loss: 1.7573 - val_accuracy: 0.4366\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 1.4652 - accuracy: 0.5247 - val_loss: 1.7548 - val_accuracy: 0.4361\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 1s 143ms/step - loss: 1.4560 - accuracy: 0.5280 - val_loss: 1.7606 - val_accuracy: 0.4365\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 1.4486 - accuracy: 0.5280 - val_loss: 1.7372 - val_accuracy: 0.4453\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 1.4383 - accuracy: 0.5312 - val_loss: 1.7204 - val_accuracy: 0.4494\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 1.4347 - accuracy: 0.5355 - val_loss: 1.7191 - val_accuracy: 0.4510\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 1s 158ms/step - loss: 1.4256 - accuracy: 0.5400 - val_loss: 1.7091 - val_accuracy: 0.4566\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.4177 - accuracy: 0.5390 - val_loss: 1.6926 - val_accuracy: 0.4607\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 1.4110 - accuracy: 0.5411 - val_loss: 1.6837 - val_accuracy: 0.4621\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 1.4002 - accuracy: 0.5461 - val_loss: 1.6636 - val_accuracy: 0.4720\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 1.4039 - accuracy: 0.5449 - val_loss: 1.6492 - val_accuracy: 0.4716\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 1.3908 - accuracy: 0.5482 - val_loss: 1.6517 - val_accuracy: 0.4700\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 1.3841 - accuracy: 0.5522 - val_loss: 1.6404 - val_accuracy: 0.4744\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 1.3838 - accuracy: 0.5509 - val_loss: 1.6280 - val_accuracy: 0.4798\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 1s 159ms/step - loss: 1.3683 - accuracy: 0.5558 - val_loss: 1.6185 - val_accuracy: 0.4818\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 1.3625 - accuracy: 0.5581 - val_loss: 1.6173 - val_accuracy: 0.4831\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 1s 159ms/step - loss: 1.3536 - accuracy: 0.5635 - val_loss: 1.6138 - val_accuracy: 0.4847\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 1.3571 - accuracy: 0.5612 - val_loss: 1.6107 - val_accuracy: 0.4844\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 1.3507 - accuracy: 0.5640 - val_loss: 1.5810 - val_accuracy: 0.4936\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 1.3337 - accuracy: 0.5662 - val_loss: 1.5600 - val_accuracy: 0.5015\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 1.3269 - accuracy: 0.5717 - val_loss: 1.5569 - val_accuracy: 0.5001\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 1.3241 - accuracy: 0.5717 - val_loss: 1.5451 - val_accuracy: 0.5066\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 1.3212 - accuracy: 0.5728 - val_loss: 1.5523 - val_accuracy: 0.5042\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 1.3114 - accuracy: 0.5744 - val_loss: 1.5384 - val_accuracy: 0.5072\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 1.3021 - accuracy: 0.5806 - val_loss: 1.5345 - val_accuracy: 0.5097\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 1s 158ms/step - loss: 1.3013 - accuracy: 0.5783 - val_loss: 1.5324 - val_accuracy: 0.5117\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 1.2846 - accuracy: 0.5839 - val_loss: 1.5256 - val_accuracy: 0.5136\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 1.2860 - accuracy: 0.5837 - val_loss: 1.5166 - val_accuracy: 0.5185\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 1.2772 - accuracy: 0.5902 - val_loss: 1.5165 - val_accuracy: 0.5132\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 1.2789 - accuracy: 0.5870 - val_loss: 1.5084 - val_accuracy: 0.5193\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 1.2668 - accuracy: 0.5930 - val_loss: 1.5056 - val_accuracy: 0.5213\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 1.2608 - accuracy: 0.5925 - val_loss: 1.4970 - val_accuracy: 0.5228\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 1.2591 - accuracy: 0.5939 - val_loss: 1.4887 - val_accuracy: 0.5282\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 1.2480 - accuracy: 0.5978 - val_loss: 1.4864 - val_accuracy: 0.5287\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 1.2374 - accuracy: 0.6006 - val_loss: 1.4905 - val_accuracy: 0.5295\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 1.2402 - accuracy: 0.6029 - val_loss: 1.4884 - val_accuracy: 0.5278\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 1.2381 - accuracy: 0.5999 - val_loss: 1.4730 - val_accuracy: 0.5307\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 1.2262 - accuracy: 0.6072 - val_loss: 1.4694 - val_accuracy: 0.5343\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 1s 141ms/step - loss: 1.2194 - accuracy: 0.6044 - val_loss: 1.4724 - val_accuracy: 0.5318\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 1s 133ms/step - loss: 1.2178 - accuracy: 0.6086 - val_loss: 1.4583 - val_accuracy: 0.5338\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 1.2074 - accuracy: 0.6148 - val_loss: 1.4745 - val_accuracy: 0.5288\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 1s 170ms/step - loss: 1.2088 - accuracy: 0.6104 - val_loss: 1.4558 - val_accuracy: 0.5348\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 1.1979 - accuracy: 0.6137 - val_loss: 1.4665 - val_accuracy: 0.5369\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 1.2021 - accuracy: 0.6159 - val_loss: 1.4329 - val_accuracy: 0.5472\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 1s 141ms/step - loss: 1.1926 - accuracy: 0.6197 - val_loss: 1.4525 - val_accuracy: 0.5429\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 1.1814 - accuracy: 0.6227 - val_loss: 1.4265 - val_accuracy: 0.5497\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 1s 141ms/step - loss: 1.1830 - accuracy: 0.6206 - val_loss: 1.4340 - val_accuracy: 0.5464\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 1.1689 - accuracy: 0.6249 - val_loss: 1.4181 - val_accuracy: 0.5540\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 1.1671 - accuracy: 0.6283 - val_loss: 1.4224 - val_accuracy: 0.5518\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 1.1611 - accuracy: 0.6297 - val_loss: 1.4189 - val_accuracy: 0.5531\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 1s 158ms/step - loss: 1.1573 - accuracy: 0.6282 - val_loss: 1.4191 - val_accuracy: 0.5551\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 1.1551 - accuracy: 0.6313 - val_loss: 1.4136 - val_accuracy: 0.5564\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 1.1494 - accuracy: 0.6334 - val_loss: 1.4230 - val_accuracy: 0.5540\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 1.1421 - accuracy: 0.6348 - val_loss: 1.4146 - val_accuracy: 0.5579\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 1.1387 - accuracy: 0.6370 - val_loss: 1.4076 - val_accuracy: 0.5591\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 1.1278 - accuracy: 0.6412 - val_loss: 1.4117 - val_accuracy: 0.5592\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 1.1247 - accuracy: 0.6406 - val_loss: 1.4119 - val_accuracy: 0.5604\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 1.1222 - accuracy: 0.6444 - val_loss: 1.4033 - val_accuracy: 0.5616\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 1s 158ms/step - loss: 1.1242 - accuracy: 0.6445 - val_loss: 1.3952 - val_accuracy: 0.5645\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 1.1107 - accuracy: 0.6502 - val_loss: 1.4069 - val_accuracy: 0.5644\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 1.1080 - accuracy: 0.6481 - val_loss: 1.3980 - val_accuracy: 0.5663\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 1.1047 - accuracy: 0.6512 - val_loss: 1.4081 - val_accuracy: 0.5580\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 1.0925 - accuracy: 0.6526 - val_loss: 1.4017 - val_accuracy: 0.5623\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 1s 158ms/step - loss: 1.1014 - accuracy: 0.6503 - val_loss: 1.3946 - val_accuracy: 0.5674\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 1s 143ms/step - loss: 1.0866 - accuracy: 0.6556 - val_loss: 1.3996 - val_accuracy: 0.5670\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 1.0922 - accuracy: 0.6516 - val_loss: 1.3999 - val_accuracy: 0.5688\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 1s 141ms/step - loss: 1.0891 - accuracy: 0.6553 - val_loss: 1.4062 - val_accuracy: 0.5634\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 1.0734 - accuracy: 0.6619 - val_loss: 1.3934 - val_accuracy: 0.5671\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 1.0775 - accuracy: 0.6629 - val_loss: 1.4067 - val_accuracy: 0.5633\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 1.0638 - accuracy: 0.6611 - val_loss: 1.3982 - val_accuracy: 0.5657\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 1s 159ms/step - loss: 1.0627 - accuracy: 0.6649 - val_loss: 1.3941 - val_accuracy: 0.5691\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 1.0618 - accuracy: 0.6683 - val_loss: 1.3929 - val_accuracy: 0.5693\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 1.0588 - accuracy: 0.6683 - val_loss: 1.4024 - val_accuracy: 0.5678\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 1.0467 - accuracy: 0.6722 - val_loss: 1.3998 - val_accuracy: 0.5681\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 1.0547 - accuracy: 0.6692 - val_loss: 1.3904 - val_accuracy: 0.5715\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 1s 141ms/step - loss: 1.0495 - accuracy: 0.6712 - val_loss: 1.3906 - val_accuracy: 0.5694\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 1.0417 - accuracy: 0.6727 - val_loss: 1.3834 - val_accuracy: 0.5724\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 1.0366 - accuracy: 0.6744 - val_loss: 1.4095 - val_accuracy: 0.5662\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 1s 141ms/step - loss: 1.0373 - accuracy: 0.6770 - val_loss: 1.3992 - val_accuracy: 0.5689\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 1.0270 - accuracy: 0.6812 - val_loss: 1.3947 - val_accuracy: 0.5691\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 1.0216 - accuracy: 0.6822 - val_loss: 1.3978 - val_accuracy: 0.5688\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 1.0224 - accuracy: 0.6832 - val_loss: 1.4040 - val_accuracy: 0.5692\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 1.0217 - accuracy: 0.6827 - val_loss: 1.3906 - val_accuracy: 0.5715\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 1.0084 - accuracy: 0.6885 - val_loss: 1.3951 - val_accuracy: 0.5706\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 1.0148 - accuracy: 0.6839 - val_loss: 1.3984 - val_accuracy: 0.5729\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 1.0045 - accuracy: 0.6883 - val_loss: 1.3987 - val_accuracy: 0.5746\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 1.0113 - accuracy: 0.6864 - val_loss: 1.3948 - val_accuracy: 0.5727\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 1.0032 - accuracy: 0.6864 - val_loss: 1.3882 - val_accuracy: 0.5717\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 1.0044 - accuracy: 0.6883 - val_loss: 1.3899 - val_accuracy: 0.5723\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.9955 - accuracy: 0.6899 - val_loss: 1.4063 - val_accuracy: 0.5702\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.9957 - accuracy: 0.6930 - val_loss: 1.4025 - val_accuracy: 0.5719\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.9853 - accuracy: 0.6951 - val_loss: 1.4187 - val_accuracy: 0.5689\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 0.9881 - accuracy: 0.6967 - val_loss: 1.4070 - val_accuracy: 0.5730\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.9824 - accuracy: 0.6948 - val_loss: 1.3978 - val_accuracy: 0.5745\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 1s 143ms/step - loss: 0.9808 - accuracy: 0.6980 - val_loss: 1.3979 - val_accuracy: 0.5731\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.9717 - accuracy: 0.7026 - val_loss: 1.3988 - val_accuracy: 0.5757\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 0.9757 - accuracy: 0.6991 - val_loss: 1.3954 - val_accuracy: 0.5780\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.9637 - accuracy: 0.7050 - val_loss: 1.3961 - val_accuracy: 0.5768\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 0.9703 - accuracy: 0.7003 - val_loss: 1.3867 - val_accuracy: 0.5784\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.9619 - accuracy: 0.7062 - val_loss: 1.3925 - val_accuracy: 0.5784\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.9565 - accuracy: 0.7082 - val_loss: 1.3916 - val_accuracy: 0.5768\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.9562 - accuracy: 0.7086 - val_loss: 1.4126 - val_accuracy: 0.5759\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 0.9539 - accuracy: 0.7058 - val_loss: 1.4057 - val_accuracy: 0.5747\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 0.9487 - accuracy: 0.7123 - val_loss: 1.4100 - val_accuracy: 0.5757\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 0.9528 - accuracy: 0.7103 - val_loss: 1.4221 - val_accuracy: 0.5728\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.9443 - accuracy: 0.7128 - val_loss: 1.4199 - val_accuracy: 0.5760\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 1s 128ms/step - loss: 0.9463 - accuracy: 0.7145 - val_loss: 1.4258 - val_accuracy: 0.5741\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 0.9465 - accuracy: 0.7101 - val_loss: 1.4261 - val_accuracy: 0.5739\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.9391 - accuracy: 0.7143 - val_loss: 1.4176 - val_accuracy: 0.5708\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.9356 - accuracy: 0.7169 - val_loss: 1.4039 - val_accuracy: 0.5775\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 1s 143ms/step - loss: 0.9309 - accuracy: 0.7161 - val_loss: 1.4328 - val_accuracy: 0.5736\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.9325 - accuracy: 0.7155 - val_loss: 1.4209 - val_accuracy: 0.5732\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.9309 - accuracy: 0.7187 - val_loss: 1.4175 - val_accuracy: 0.5729\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.9144 - accuracy: 0.7245 - val_loss: 1.4198 - val_accuracy: 0.5792\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 0.9247 - accuracy: 0.7177 - val_loss: 1.4295 - val_accuracy: 0.5773\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.9184 - accuracy: 0.7214 - val_loss: 1.4190 - val_accuracy: 0.5789\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 1s 141ms/step - loss: 0.9252 - accuracy: 0.7205 - val_loss: 1.4227 - val_accuracy: 0.5747\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.9200 - accuracy: 0.7212 - val_loss: 1.4238 - val_accuracy: 0.5755\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 1s 142ms/step - loss: 0.9174 - accuracy: 0.7214 - val_loss: 1.4212 - val_accuracy: 0.5726\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.9056 - accuracy: 0.7291 - val_loss: 1.4336 - val_accuracy: 0.5771\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 1s 159ms/step - loss: 0.9097 - accuracy: 0.7257 - val_loss: 1.4235 - val_accuracy: 0.5823\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 0.9063 - accuracy: 0.7293 - val_loss: 1.4437 - val_accuracy: 0.5744\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.9045 - accuracy: 0.7281 - val_loss: 1.4286 - val_accuracy: 0.5783\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.8987 - accuracy: 0.7312 - val_loss: 1.4337 - val_accuracy: 0.5788\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 0.9002 - accuracy: 0.7302 - val_loss: 1.4228 - val_accuracy: 0.5857\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.8933 - accuracy: 0.7322 - val_loss: 1.4390 - val_accuracy: 0.5777\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.9008 - accuracy: 0.7318 - val_loss: 1.4359 - val_accuracy: 0.5803\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 1s 133ms/step - loss: 0.8923 - accuracy: 0.7308 - val_loss: 1.4251 - val_accuracy: 0.5801\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 1s 143ms/step - loss: 0.8993 - accuracy: 0.7309 - val_loss: 1.4297 - val_accuracy: 0.5771\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.8926 - accuracy: 0.7336 - val_loss: 1.4388 - val_accuracy: 0.5771\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.8901 - accuracy: 0.7339 - val_loss: 1.4320 - val_accuracy: 0.5802\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.8800 - accuracy: 0.7397 - val_loss: 1.4395 - val_accuracy: 0.5765\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.8923 - accuracy: 0.7322 - val_loss: 1.4343 - val_accuracy: 0.5784\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 0.8805 - accuracy: 0.7356 - val_loss: 1.4349 - val_accuracy: 0.5762\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 0.8836 - accuracy: 0.7354 - val_loss: 1.4425 - val_accuracy: 0.5770\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.8777 - accuracy: 0.7400 - val_loss: 1.4538 - val_accuracy: 0.5778\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.8812 - accuracy: 0.7355 - val_loss: 1.4448 - val_accuracy: 0.5813\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.8778 - accuracy: 0.7388 - val_loss: 1.4357 - val_accuracy: 0.5799\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 1s 141ms/step - loss: 0.8736 - accuracy: 0.7407 - val_loss: 1.4373 - val_accuracy: 0.5787\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.8619 - accuracy: 0.7446 - val_loss: 1.4398 - val_accuracy: 0.5787\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 0.8712 - accuracy: 0.7426 - val_loss: 1.4467 - val_accuracy: 0.5729\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.8688 - accuracy: 0.7436 - val_loss: 1.4397 - val_accuracy: 0.5799\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 0.8658 - accuracy: 0.7448 - val_loss: 1.4502 - val_accuracy: 0.5760\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.8719 - accuracy: 0.7417 - val_loss: 1.4507 - val_accuracy: 0.5744\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 1s 143ms/step - loss: 0.8644 - accuracy: 0.7432 - val_loss: 1.4489 - val_accuracy: 0.5773\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.8604 - accuracy: 0.7459 - val_loss: 1.4416 - val_accuracy: 0.5797\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 1s 142ms/step - loss: 0.8628 - accuracy: 0.7465 - val_loss: 1.4437 - val_accuracy: 0.5777\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.8605 - accuracy: 0.7458 - val_loss: 1.4528 - val_accuracy: 0.5763\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.8522 - accuracy: 0.7488 - val_loss: 1.4395 - val_accuracy: 0.5811\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.8574 - accuracy: 0.7473 - val_loss: 1.4475 - val_accuracy: 0.5807\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.8549 - accuracy: 0.7468 - val_loss: 1.4474 - val_accuracy: 0.5769\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.8543 - accuracy: 0.7456 - val_loss: 1.4565 - val_accuracy: 0.5802\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.8469 - accuracy: 0.7491 - val_loss: 1.4479 - val_accuracy: 0.5833\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 1s 133ms/step - loss: 0.8495 - accuracy: 0.7524 - val_loss: 1.4579 - val_accuracy: 0.5790\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.8436 - accuracy: 0.7508 - val_loss: 1.4588 - val_accuracy: 0.5780\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.8463 - accuracy: 0.7508 - val_loss: 1.4544 - val_accuracy: 0.5794\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.8436 - accuracy: 0.7547 - val_loss: 1.4574 - val_accuracy: 0.5782\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 0.8343 - accuracy: 0.7581 - val_loss: 1.4588 - val_accuracy: 0.5828\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.8415 - accuracy: 0.7509 - val_loss: 1.4594 - val_accuracy: 0.5787\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.8407 - accuracy: 0.7555 - val_loss: 1.4677 - val_accuracy: 0.5812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Amk91Chjzqz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "a91b625b-c68e-4075-e709-291bf31c9944"
      },
      "source": [
        "# Plot the training loss and validation loss\n",
        "model.load_weights('/content/checkpoint')\n",
        "train_loss, train_acc = model.evaluate(x_train,y_train,verbose=0)\n",
        "test_loss, test_acc = model.evaluate(x_test,y_test,verbose=0)\n",
        "val_acc = max(history.history['val_accuracy'])\n",
        "val_loss = min(history.history['val_loss'])\n",
        "\n",
        "print('Train set')\n",
        "print('accuracy =',train_acc)\n",
        "print('loss =',train_loss)\n",
        "print('==================')\n",
        "print('Test set')\n",
        "print('accuracy =',test_acc)\n",
        "print('loss =',test_loss)\n",
        "print('==================')\n",
        "print('Validation')\n",
        "print('accuracy =',val_acc)\n",
        "print('loss =',val_loss)\n",
        "print('==================')\n",
        "print()\n",
        "\n",
        "loss_train = np.array(history.history['loss']) \n",
        "loss_test = np.array(history.history['val_loss'])\n",
        "\n",
        "x = np.arange(0,loss_train.shape[0])\n",
        "plt.plot(x, loss_train, label='Training loss')\n",
        "plt.plot(x, loss_test, label='Validation loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Training loss','Validation loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set\n",
            "accuracy = 0.8273800015449524\n",
            "loss = 0.6948694586753845\n",
            "==================\n",
            "Test set\n",
            "accuracy = 0.571399986743927\n",
            "loss = 1.4143136739730835\n",
            "==================\n",
            "Validation\n",
            "accuracy = 0.5856999754905701\n",
            "loss = 1.3834102153778076\n",
            "==================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fEbEqLfADJu"
      },
      "source": [
        "## Question 2\n",
        "\n",
        "Construct a convolutional neural network using your own structure. Try to maximize the prediction accuracy of your model.\n",
        "\n",
        "After the training process, print the training, validation, and test accuracies, as well as plot the training loss and validation loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTrbgdtZknEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18fcdfd-b052-4833-ee10-18794368117e"
      },
      "source": [
        "# Your implementation for Question 2\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "(x_train, y_train) , (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Preprocessing\n",
        "y_train = tf.one_hot(y_train, 10)\n",
        "y_train = tf.reshape(y_train,[-1,10])\n",
        "y_test = tf.one_hot(y_test, 10)\n",
        "y_test = tf.reshape(y_test,[-1,10])\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "x_train = x_train.reshape((-1,32,32,3))\n",
        "x_test = x_test.reshape((-1,32,32,3))\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Input(shape=(32,32,3)),\n",
        "  tf.keras.layers.Conv2D(64,(3,3),padding='same'),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.ReLU(),\n",
        "  tf.keras.layers.MaxPooling2D((3,3)),\n",
        "  tf.keras.layers.SpatialDropout2D(0.2),\n",
        "  tf.keras.layers.Conv2D(128,(3,3),padding='same'),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.ReLU(),\n",
        "  tf.keras.layers.MaxPooling2D((3,3)),\n",
        "   tf.keras.layers.SpatialDropout2D(0.3),\n",
        "  tf.keras.layers.Conv2D(256,(3,3),padding='same'),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.ReLU(),\n",
        "  tf.keras.layers.MaxPooling2D((3,3)),\n",
        "  tf.keras.layers.SpatialDropout2D(0.4),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512,activation='relu',\n",
        "    kernel_regularizer = tf.keras.regularizers.l2(1e-4)),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dropout(0.3),\n",
        "  tf.keras.layers.Dense(256,activation='relu',\n",
        "    kernel_regularizer = tf.keras.regularizers.l2(1e-4)),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(128,activation='relu',\n",
        "    kernel_regularizer = tf.keras.regularizers.l2(1e-4)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "             loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model_checkpoint_callback2 = tf.keras.callbacks.ModelCheckpoint(\n",
        "             filepath = '/content/checkpoint2',\n",
        "             save_weights_only = True,\n",
        "             monitor = 'val_accuracy',\n",
        "             mode = 'max',\n",
        "             save_best_only = True\n",
        ")\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=200, batch_size=512,\n",
        "                    shuffle=True, validation_split=0.2, callbacks=[model_checkpoint_callback2])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "79/79 [==============================] - 36s 81ms/step - loss: 2.6529 - accuracy: 0.1843 - val_loss: 3.0100 - val_accuracy: 0.0997\n",
            "Epoch 2/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 2.0745 - accuracy: 0.2824 - val_loss: 3.5173 - val_accuracy: 0.0997\n",
            "Epoch 3/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 1.8651 - accuracy: 0.3410 - val_loss: 3.5371 - val_accuracy: 0.1027\n",
            "Epoch 4/200\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 1.7414 - accuracy: 0.3864 - val_loss: 3.4304 - val_accuracy: 0.0981\n",
            "Epoch 5/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 1.6477 - accuracy: 0.4243 - val_loss: 2.9903 - val_accuracy: 0.1639\n",
            "Epoch 6/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 1.5670 - accuracy: 0.4558 - val_loss: 2.4981 - val_accuracy: 0.2543\n",
            "Epoch 7/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 1.5086 - accuracy: 0.4780 - val_loss: 1.7662 - val_accuracy: 0.4126\n",
            "Epoch 8/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 1.4386 - accuracy: 0.5078 - val_loss: 1.5215 - val_accuracy: 0.4876\n",
            "Epoch 9/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 1.4010 - accuracy: 0.5200 - val_loss: 1.2244 - val_accuracy: 0.5901\n",
            "Epoch 10/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 1.3532 - accuracy: 0.5391 - val_loss: 1.1928 - val_accuracy: 0.5959\n",
            "Epoch 11/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 1.3264 - accuracy: 0.5542 - val_loss: 1.1684 - val_accuracy: 0.6045\n",
            "Epoch 12/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 1.2819 - accuracy: 0.5721 - val_loss: 1.1019 - val_accuracy: 0.6331\n",
            "Epoch 13/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 1.2475 - accuracy: 0.5806 - val_loss: 1.1751 - val_accuracy: 0.6024\n",
            "Epoch 14/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 1.2230 - accuracy: 0.5917 - val_loss: 1.1040 - val_accuracy: 0.6316\n",
            "Epoch 15/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 1.1995 - accuracy: 0.6004 - val_loss: 1.0358 - val_accuracy: 0.6582\n",
            "Epoch 16/200\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 1.1693 - accuracy: 0.6119 - val_loss: 1.0971 - val_accuracy: 0.6359\n",
            "Epoch 17/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 1.1398 - accuracy: 0.6227 - val_loss: 1.0607 - val_accuracy: 0.6421\n",
            "Epoch 18/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 1.1173 - accuracy: 0.6341 - val_loss: 1.0298 - val_accuracy: 0.6540\n",
            "Epoch 19/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 1.0975 - accuracy: 0.6402 - val_loss: 0.9957 - val_accuracy: 0.6713\n",
            "Epoch 20/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 1.0790 - accuracy: 0.6465 - val_loss: 0.9656 - val_accuracy: 0.6864\n",
            "Epoch 21/200\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 1.0608 - accuracy: 0.6541 - val_loss: 0.9644 - val_accuracy: 0.6842\n",
            "Epoch 22/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 1.0245 - accuracy: 0.6680 - val_loss: 0.9247 - val_accuracy: 0.7020\n",
            "Epoch 23/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 1.0241 - accuracy: 0.6665 - val_loss: 0.9181 - val_accuracy: 0.7021\n",
            "Epoch 24/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.9939 - accuracy: 0.6795 - val_loss: 0.9072 - val_accuracy: 0.7071\n",
            "Epoch 25/200\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 0.9799 - accuracy: 0.6832 - val_loss: 0.9197 - val_accuracy: 0.6975\n",
            "Epoch 26/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.9653 - accuracy: 0.6879 - val_loss: 0.8953 - val_accuracy: 0.7096\n",
            "Epoch 27/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.9510 - accuracy: 0.6946 - val_loss: 0.8700 - val_accuracy: 0.7229\n",
            "Epoch 28/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.9295 - accuracy: 0.6995 - val_loss: 0.8265 - val_accuracy: 0.7384\n",
            "Epoch 29/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.9186 - accuracy: 0.7035 - val_loss: 0.8360 - val_accuracy: 0.7327\n",
            "Epoch 30/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.8999 - accuracy: 0.7119 - val_loss: 0.8192 - val_accuracy: 0.7399\n",
            "Epoch 31/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.8907 - accuracy: 0.7147 - val_loss: 0.7991 - val_accuracy: 0.7464\n",
            "Epoch 32/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.8751 - accuracy: 0.7204 - val_loss: 0.8328 - val_accuracy: 0.7302\n",
            "Epoch 33/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.8672 - accuracy: 0.7227 - val_loss: 0.8843 - val_accuracy: 0.7200\n",
            "Epoch 34/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.8541 - accuracy: 0.7250 - val_loss: 0.7851 - val_accuracy: 0.7519\n",
            "Epoch 35/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.8371 - accuracy: 0.7326 - val_loss: 0.8197 - val_accuracy: 0.7384\n",
            "Epoch 36/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.8235 - accuracy: 0.7361 - val_loss: 0.7453 - val_accuracy: 0.7644\n",
            "Epoch 37/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.8171 - accuracy: 0.7398 - val_loss: 0.7757 - val_accuracy: 0.7576\n",
            "Epoch 38/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.8031 - accuracy: 0.7424 - val_loss: 0.7927 - val_accuracy: 0.7464\n",
            "Epoch 39/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.8005 - accuracy: 0.7448 - val_loss: 0.8891 - val_accuracy: 0.7170\n",
            "Epoch 40/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.7860 - accuracy: 0.7491 - val_loss: 0.7978 - val_accuracy: 0.7428\n",
            "Epoch 41/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.7752 - accuracy: 0.7527 - val_loss: 0.7372 - val_accuracy: 0.7647\n",
            "Epoch 42/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.7598 - accuracy: 0.7574 - val_loss: 0.7303 - val_accuracy: 0.7720\n",
            "Epoch 43/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.7508 - accuracy: 0.7610 - val_loss: 0.7405 - val_accuracy: 0.7650\n",
            "Epoch 44/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.7451 - accuracy: 0.7626 - val_loss: 0.7362 - val_accuracy: 0.7686\n",
            "Epoch 45/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.7414 - accuracy: 0.7632 - val_loss: 0.7196 - val_accuracy: 0.7770\n",
            "Epoch 46/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.7307 - accuracy: 0.7664 - val_loss: 0.7438 - val_accuracy: 0.7638\n",
            "Epoch 47/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.7259 - accuracy: 0.7692 - val_loss: 0.7412 - val_accuracy: 0.7693\n",
            "Epoch 48/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.7138 - accuracy: 0.7727 - val_loss: 0.7008 - val_accuracy: 0.7812\n",
            "Epoch 49/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.7107 - accuracy: 0.7737 - val_loss: 0.7552 - val_accuracy: 0.7599\n",
            "Epoch 50/200\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 0.6967 - accuracy: 0.7764 - val_loss: 0.7526 - val_accuracy: 0.7619\n",
            "Epoch 51/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.6977 - accuracy: 0.7797 - val_loss: 0.7206 - val_accuracy: 0.7717\n",
            "Epoch 52/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.6893 - accuracy: 0.7811 - val_loss: 0.7138 - val_accuracy: 0.7731\n",
            "Epoch 53/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.6801 - accuracy: 0.7831 - val_loss: 0.7161 - val_accuracy: 0.7711\n",
            "Epoch 54/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.6695 - accuracy: 0.7876 - val_loss: 0.6908 - val_accuracy: 0.7822\n",
            "Epoch 55/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.6621 - accuracy: 0.7883 - val_loss: 0.7040 - val_accuracy: 0.7822\n",
            "Epoch 56/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.6631 - accuracy: 0.7891 - val_loss: 0.7647 - val_accuracy: 0.7543\n",
            "Epoch 57/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.6537 - accuracy: 0.7925 - val_loss: 0.7108 - val_accuracy: 0.7793\n",
            "Epoch 58/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.6473 - accuracy: 0.7934 - val_loss: 0.7415 - val_accuracy: 0.7651\n",
            "Epoch 59/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.6457 - accuracy: 0.7964 - val_loss: 0.6941 - val_accuracy: 0.7840\n",
            "Epoch 60/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.6380 - accuracy: 0.7985 - val_loss: 0.7757 - val_accuracy: 0.7538\n",
            "Epoch 61/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.6454 - accuracy: 0.7964 - val_loss: 0.8445 - val_accuracy: 0.7367\n",
            "Epoch 62/200\n",
            "79/79 [==============================] - 6s 75ms/step - loss: 0.6329 - accuracy: 0.7991 - val_loss: 0.6884 - val_accuracy: 0.7826\n",
            "Epoch 63/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.6260 - accuracy: 0.8003 - val_loss: 0.6791 - val_accuracy: 0.7898\n",
            "Epoch 64/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.6262 - accuracy: 0.8014 - val_loss: 0.7261 - val_accuracy: 0.7730\n",
            "Epoch 65/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.6203 - accuracy: 0.8030 - val_loss: 0.6942 - val_accuracy: 0.7841\n",
            "Epoch 66/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.6138 - accuracy: 0.8082 - val_loss: 0.7705 - val_accuracy: 0.7594\n",
            "Epoch 67/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.6035 - accuracy: 0.8097 - val_loss: 0.7233 - val_accuracy: 0.7756\n",
            "Epoch 68/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5996 - accuracy: 0.8113 - val_loss: 0.7418 - val_accuracy: 0.7703\n",
            "Epoch 69/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.6029 - accuracy: 0.8109 - val_loss: 0.7053 - val_accuracy: 0.7825\n",
            "Epoch 70/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5926 - accuracy: 0.8126 - val_loss: 0.6843 - val_accuracy: 0.7862\n",
            "Epoch 71/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5887 - accuracy: 0.8149 - val_loss: 0.7529 - val_accuracy: 0.7700\n",
            "Epoch 72/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5940 - accuracy: 0.8115 - val_loss: 0.6792 - val_accuracy: 0.7885\n",
            "Epoch 73/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5906 - accuracy: 0.8141 - val_loss: 0.7798 - val_accuracy: 0.7574\n",
            "Epoch 74/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5842 - accuracy: 0.8151 - val_loss: 0.6902 - val_accuracy: 0.7858\n",
            "Epoch 75/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5844 - accuracy: 0.8173 - val_loss: 0.7353 - val_accuracy: 0.7724\n",
            "Epoch 76/200\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 0.5771 - accuracy: 0.8163 - val_loss: 0.6820 - val_accuracy: 0.7840\n",
            "Epoch 77/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5759 - accuracy: 0.8178 - val_loss: 0.7265 - val_accuracy: 0.7739\n",
            "Epoch 78/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5776 - accuracy: 0.8185 - val_loss: 0.7580 - val_accuracy: 0.7606\n",
            "Epoch 79/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5641 - accuracy: 0.8224 - val_loss: 0.6977 - val_accuracy: 0.7827\n",
            "Epoch 80/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5597 - accuracy: 0.8251 - val_loss: 0.7051 - val_accuracy: 0.7849\n",
            "Epoch 81/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5667 - accuracy: 0.8229 - val_loss: 0.6712 - val_accuracy: 0.7905\n",
            "Epoch 82/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5610 - accuracy: 0.8227 - val_loss: 0.8046 - val_accuracy: 0.7539\n",
            "Epoch 83/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5559 - accuracy: 0.8256 - val_loss: 0.7286 - val_accuracy: 0.7777\n",
            "Epoch 84/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5614 - accuracy: 0.8218 - val_loss: 0.7001 - val_accuracy: 0.7895\n",
            "Epoch 85/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5499 - accuracy: 0.8262 - val_loss: 0.6977 - val_accuracy: 0.7816\n",
            "Epoch 86/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5495 - accuracy: 0.8268 - val_loss: 0.7066 - val_accuracy: 0.7834\n",
            "Epoch 87/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5442 - accuracy: 0.8277 - val_loss: 0.7360 - val_accuracy: 0.7728\n",
            "Epoch 88/200\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.5350 - accuracy: 0.8324 - val_loss: 0.6827 - val_accuracy: 0.7907\n",
            "Epoch 89/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5369 - accuracy: 0.8313 - val_loss: 0.6917 - val_accuracy: 0.7893\n",
            "Epoch 90/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5335 - accuracy: 0.8333 - val_loss: 0.6752 - val_accuracy: 0.7906\n",
            "Epoch 91/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5332 - accuracy: 0.8338 - val_loss: 0.7487 - val_accuracy: 0.7729\n",
            "Epoch 92/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5289 - accuracy: 0.8341 - val_loss: 0.6878 - val_accuracy: 0.7858\n",
            "Epoch 93/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5278 - accuracy: 0.8366 - val_loss: 0.6811 - val_accuracy: 0.7919\n",
            "Epoch 94/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5258 - accuracy: 0.8350 - val_loss: 0.7227 - val_accuracy: 0.7756\n",
            "Epoch 95/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5259 - accuracy: 0.8357 - val_loss: 0.7128 - val_accuracy: 0.7819\n",
            "Epoch 96/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5270 - accuracy: 0.8354 - val_loss: 0.7116 - val_accuracy: 0.7809\n",
            "Epoch 97/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5175 - accuracy: 0.8389 - val_loss: 0.7210 - val_accuracy: 0.7793\n",
            "Epoch 98/200\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.5117 - accuracy: 0.8394 - val_loss: 0.6696 - val_accuracy: 0.7938\n",
            "Epoch 99/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5144 - accuracy: 0.8386 - val_loss: 0.7613 - val_accuracy: 0.7724\n",
            "Epoch 100/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5230 - accuracy: 0.8362 - val_loss: 0.7098 - val_accuracy: 0.7823\n",
            "Epoch 101/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5103 - accuracy: 0.8401 - val_loss: 0.7511 - val_accuracy: 0.7731\n",
            "Epoch 102/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5166 - accuracy: 0.8384 - val_loss: 0.7564 - val_accuracy: 0.7673\n",
            "Epoch 103/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5101 - accuracy: 0.8409 - val_loss: 0.6977 - val_accuracy: 0.7857\n",
            "Epoch 104/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5049 - accuracy: 0.8416 - val_loss: 0.6658 - val_accuracy: 0.7952\n",
            "Epoch 105/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5089 - accuracy: 0.8411 - val_loss: 0.7324 - val_accuracy: 0.7786\n",
            "Epoch 106/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5101 - accuracy: 0.8408 - val_loss: 0.6839 - val_accuracy: 0.7902\n",
            "Epoch 107/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5021 - accuracy: 0.8426 - val_loss: 0.7156 - val_accuracy: 0.7820\n",
            "Epoch 108/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4989 - accuracy: 0.8456 - val_loss: 0.6830 - val_accuracy: 0.7939\n",
            "Epoch 109/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.5017 - accuracy: 0.8425 - val_loss: 0.6902 - val_accuracy: 0.7925\n",
            "Epoch 110/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4971 - accuracy: 0.8460 - val_loss: 0.6899 - val_accuracy: 0.7902\n",
            "Epoch 111/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4914 - accuracy: 0.8490 - val_loss: 0.6976 - val_accuracy: 0.7863\n",
            "Epoch 112/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4898 - accuracy: 0.8464 - val_loss: 0.7952 - val_accuracy: 0.7638\n",
            "Epoch 113/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.5032 - accuracy: 0.8436 - val_loss: 0.6757 - val_accuracy: 0.7938\n",
            "Epoch 114/200\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.4876 - accuracy: 0.8507 - val_loss: 0.6636 - val_accuracy: 0.7982\n",
            "Epoch 115/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4969 - accuracy: 0.8453 - val_loss: 0.7505 - val_accuracy: 0.7765\n",
            "Epoch 116/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4906 - accuracy: 0.8483 - val_loss: 0.7120 - val_accuracy: 0.7854\n",
            "Epoch 117/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4824 - accuracy: 0.8501 - val_loss: 0.7031 - val_accuracy: 0.7873\n",
            "Epoch 118/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4912 - accuracy: 0.8475 - val_loss: 0.6891 - val_accuracy: 0.7893\n",
            "Epoch 119/200\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.4779 - accuracy: 0.8514 - val_loss: 0.6813 - val_accuracy: 0.7990\n",
            "Epoch 120/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4764 - accuracy: 0.8510 - val_loss: 0.6892 - val_accuracy: 0.7915\n",
            "Epoch 121/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4836 - accuracy: 0.8512 - val_loss: 0.6972 - val_accuracy: 0.7882\n",
            "Epoch 122/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4787 - accuracy: 0.8510 - val_loss: 0.7095 - val_accuracy: 0.7880\n",
            "Epoch 123/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4817 - accuracy: 0.8516 - val_loss: 0.7060 - val_accuracy: 0.7896\n",
            "Epoch 124/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4772 - accuracy: 0.8515 - val_loss: 0.7082 - val_accuracy: 0.7891\n",
            "Epoch 125/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4820 - accuracy: 0.8500 - val_loss: 0.7181 - val_accuracy: 0.7810\n",
            "Epoch 126/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4736 - accuracy: 0.8527 - val_loss: 0.6940 - val_accuracy: 0.7926\n",
            "Epoch 127/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4697 - accuracy: 0.8530 - val_loss: 0.7253 - val_accuracy: 0.7840\n",
            "Epoch 128/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4715 - accuracy: 0.8544 - val_loss: 0.6877 - val_accuracy: 0.7953\n",
            "Epoch 129/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4640 - accuracy: 0.8559 - val_loss: 0.6848 - val_accuracy: 0.7976\n",
            "Epoch 130/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4668 - accuracy: 0.8564 - val_loss: 0.7128 - val_accuracy: 0.7871\n",
            "Epoch 131/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4623 - accuracy: 0.8572 - val_loss: 0.7160 - val_accuracy: 0.7861\n",
            "Epoch 132/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4614 - accuracy: 0.8575 - val_loss: 0.6904 - val_accuracy: 0.7913\n",
            "Epoch 133/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4619 - accuracy: 0.8579 - val_loss: 0.6873 - val_accuracy: 0.7924\n",
            "Epoch 134/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4598 - accuracy: 0.8565 - val_loss: 0.7642 - val_accuracy: 0.7770\n",
            "Epoch 135/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4652 - accuracy: 0.8553 - val_loss: 0.7060 - val_accuracy: 0.7891\n",
            "Epoch 136/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4595 - accuracy: 0.8588 - val_loss: 0.6767 - val_accuracy: 0.8001\n",
            "Epoch 137/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4570 - accuracy: 0.8594 - val_loss: 0.6764 - val_accuracy: 0.7971\n",
            "Epoch 138/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4586 - accuracy: 0.8585 - val_loss: 0.7338 - val_accuracy: 0.7805\n",
            "Epoch 139/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4582 - accuracy: 0.8589 - val_loss: 0.6834 - val_accuracy: 0.7941\n",
            "Epoch 140/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4534 - accuracy: 0.8597 - val_loss: 0.6929 - val_accuracy: 0.7939\n",
            "Epoch 141/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4470 - accuracy: 0.8628 - val_loss: 0.6881 - val_accuracy: 0.7962\n",
            "Epoch 142/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4503 - accuracy: 0.8615 - val_loss: 0.6755 - val_accuracy: 0.7995\n",
            "Epoch 143/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4531 - accuracy: 0.8619 - val_loss: 0.6872 - val_accuracy: 0.7928\n",
            "Epoch 144/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4507 - accuracy: 0.8591 - val_loss: 0.7120 - val_accuracy: 0.7878\n",
            "Epoch 145/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4481 - accuracy: 0.8609 - val_loss: 0.7038 - val_accuracy: 0.7912\n",
            "Epoch 146/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4447 - accuracy: 0.8651 - val_loss: 0.7030 - val_accuracy: 0.7939\n",
            "Epoch 147/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4448 - accuracy: 0.8605 - val_loss: 0.7245 - val_accuracy: 0.7865\n",
            "Epoch 148/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4471 - accuracy: 0.8625 - val_loss: 0.7035 - val_accuracy: 0.7889\n",
            "Epoch 149/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4501 - accuracy: 0.8608 - val_loss: 0.7138 - val_accuracy: 0.7892\n",
            "Epoch 150/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4388 - accuracy: 0.8636 - val_loss: 0.7104 - val_accuracy: 0.7881\n",
            "Epoch 151/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4513 - accuracy: 0.8608 - val_loss: 0.6829 - val_accuracy: 0.7943\n",
            "Epoch 152/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4455 - accuracy: 0.8627 - val_loss: 0.6893 - val_accuracy: 0.7976\n",
            "Epoch 153/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4550 - accuracy: 0.8593 - val_loss: 0.6784 - val_accuracy: 0.7975\n",
            "Epoch 154/200\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.4403 - accuracy: 0.8626 - val_loss: 0.6754 - val_accuracy: 0.8014\n",
            "Epoch 155/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4386 - accuracy: 0.8647 - val_loss: 0.7046 - val_accuracy: 0.7949\n",
            "Epoch 156/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4370 - accuracy: 0.8650 - val_loss: 0.6982 - val_accuracy: 0.7944\n",
            "Epoch 157/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4316 - accuracy: 0.8662 - val_loss: 0.6897 - val_accuracy: 0.7958\n",
            "Epoch 158/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4366 - accuracy: 0.8651 - val_loss: 0.7072 - val_accuracy: 0.7889\n",
            "Epoch 159/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4291 - accuracy: 0.8697 - val_loss: 0.7213 - val_accuracy: 0.7848\n",
            "Epoch 160/200\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.4344 - accuracy: 0.8657 - val_loss: 0.6819 - val_accuracy: 0.7960\n",
            "Epoch 161/200\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.4365 - accuracy: 0.8663 - val_loss: 0.6986 - val_accuracy: 0.7969\n",
            "Epoch 162/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4452 - accuracy: 0.8621 - val_loss: 0.6973 - val_accuracy: 0.7936\n",
            "Epoch 163/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4343 - accuracy: 0.8668 - val_loss: 0.6925 - val_accuracy: 0.7966\n",
            "Epoch 164/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4317 - accuracy: 0.8673 - val_loss: 0.7412 - val_accuracy: 0.7841\n",
            "Epoch 165/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4264 - accuracy: 0.8670 - val_loss: 0.6847 - val_accuracy: 0.7993\n",
            "Epoch 166/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4393 - accuracy: 0.8629 - val_loss: 0.7593 - val_accuracy: 0.7761\n",
            "Epoch 167/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4270 - accuracy: 0.8695 - val_loss: 0.6981 - val_accuracy: 0.7951\n",
            "Epoch 168/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4273 - accuracy: 0.8695 - val_loss: 0.6995 - val_accuracy: 0.7954\n",
            "Epoch 169/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4285 - accuracy: 0.8694 - val_loss: 0.7520 - val_accuracy: 0.7781\n",
            "Epoch 170/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4218 - accuracy: 0.8688 - val_loss: 0.6885 - val_accuracy: 0.7945\n",
            "Epoch 171/200\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.4338 - accuracy: 0.8676 - val_loss: 0.7005 - val_accuracy: 0.7917\n",
            "Epoch 172/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4301 - accuracy: 0.8698 - val_loss: 0.6813 - val_accuracy: 0.7985\n",
            "Epoch 173/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4249 - accuracy: 0.8673 - val_loss: 0.6677 - val_accuracy: 0.8006\n",
            "Epoch 174/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4299 - accuracy: 0.8673 - val_loss: 0.6847 - val_accuracy: 0.7986\n",
            "Epoch 175/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4326 - accuracy: 0.8678 - val_loss: 0.7373 - val_accuracy: 0.7860\n",
            "Epoch 176/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4305 - accuracy: 0.8702 - val_loss: 0.7180 - val_accuracy: 0.7916\n",
            "Epoch 177/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4162 - accuracy: 0.8720 - val_loss: 0.7098 - val_accuracy: 0.7901\n",
            "Epoch 178/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4194 - accuracy: 0.8718 - val_loss: 0.6995 - val_accuracy: 0.7934\n",
            "Epoch 179/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4239 - accuracy: 0.8704 - val_loss: 0.7281 - val_accuracy: 0.7873\n",
            "Epoch 180/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4206 - accuracy: 0.8688 - val_loss: 0.7371 - val_accuracy: 0.7869\n",
            "Epoch 181/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4256 - accuracy: 0.8685 - val_loss: 0.7263 - val_accuracy: 0.7864\n",
            "Epoch 182/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4125 - accuracy: 0.8745 - val_loss: 0.6999 - val_accuracy: 0.7922\n",
            "Epoch 183/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4151 - accuracy: 0.8707 - val_loss: 0.7221 - val_accuracy: 0.7930\n",
            "Epoch 184/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4180 - accuracy: 0.8729 - val_loss: 0.7031 - val_accuracy: 0.7938\n",
            "Epoch 185/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4076 - accuracy: 0.8744 - val_loss: 0.7104 - val_accuracy: 0.7927\n",
            "Epoch 186/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4086 - accuracy: 0.8757 - val_loss: 0.6993 - val_accuracy: 0.7921\n",
            "Epoch 187/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4229 - accuracy: 0.8720 - val_loss: 0.6953 - val_accuracy: 0.7971\n",
            "Epoch 188/200\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.4117 - accuracy: 0.8743 - val_loss: 0.6945 - val_accuracy: 0.7998\n",
            "Epoch 189/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4109 - accuracy: 0.8752 - val_loss: 0.7116 - val_accuracy: 0.7927\n",
            "Epoch 190/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4107 - accuracy: 0.8755 - val_loss: 0.7203 - val_accuracy: 0.7874\n",
            "Epoch 191/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4103 - accuracy: 0.8737 - val_loss: 0.7077 - val_accuracy: 0.7944\n",
            "Epoch 192/200\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.4158 - accuracy: 0.8730 - val_loss: 0.6861 - val_accuracy: 0.7996\n",
            "Epoch 193/200\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.4080 - accuracy: 0.8745 - val_loss: 0.7165 - val_accuracy: 0.7905\n",
            "Epoch 194/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4091 - accuracy: 0.8735 - val_loss: 0.6931 - val_accuracy: 0.7963\n",
            "Epoch 195/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4094 - accuracy: 0.8753 - val_loss: 0.7489 - val_accuracy: 0.7825\n",
            "Epoch 196/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4088 - accuracy: 0.8760 - val_loss: 0.6897 - val_accuracy: 0.7974\n",
            "Epoch 197/200\n",
            "79/79 [==============================] - 6s 72ms/step - loss: 0.4061 - accuracy: 0.8754 - val_loss: 0.6870 - val_accuracy: 0.7990\n",
            "Epoch 198/200\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.4047 - accuracy: 0.8760 - val_loss: 0.7224 - val_accuracy: 0.7879\n",
            "Epoch 199/200\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.4137 - accuracy: 0.8729 - val_loss: 0.6998 - val_accuracy: 0.7938\n",
            "Epoch 200/200\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.4120 - accuracy: 0.8741 - val_loss: 0.6837 - val_accuracy: 0.8034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN2z77iAkpft",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "be3a8c83-3063-4a28-c136-af412e086982"
      },
      "source": [
        "# Plot the training loss and validation loss\n",
        "model.load_weights('/content/checkpoint2')\n",
        "train_loss, train_acc = model.evaluate(x_train,y_train,verbose=0)\n",
        "test_loss, test_acc = model.evaluate(x_test,y_test,verbose=0)\n",
        "val_acc = max(history.history['val_accuracy'])\n",
        "val_loss = min(history.history['val_loss'])\n",
        "\n",
        "print('Train set')\n",
        "print('accuracy =',train_acc)\n",
        "print('loss =',train_loss)\n",
        "print('==================')\n",
        "print('Test set')\n",
        "print('accuracy =',test_acc)\n",
        "print('loss =',test_loss)\n",
        "print('==================')\n",
        "print('validation')\n",
        "print('accuracy =',val_acc)\n",
        "print('loss =',val_loss)\n",
        "print('==================')\n",
        "print()\n",
        "\n",
        "loss_train = np.array(history.history['loss']) \n",
        "loss_test = np.array(history.history['val_loss'])\n",
        "\n",
        "x = np.arange(0,loss_train.shape[0])\n",
        "plt.plot(x, loss_train, label='Training loss')\n",
        "plt.plot(x, loss_test, label='Validation loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Training loss','Validation loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set\n",
            "accuracy = 0.954259991645813\n",
            "loss = 0.21426187455654144\n",
            "==================\n",
            "Test set\n",
            "accuracy = 0.7972999811172485\n",
            "loss = 0.6932368874549866\n",
            "==================\n",
            "validation\n",
            "accuracy = 0.8033999800682068\n",
            "loss = 0.6635981202125549\n",
            "==================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}